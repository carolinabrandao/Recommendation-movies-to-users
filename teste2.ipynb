{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>659715</th>\n",
       "      <td>3d7e93cbd0</td>\n",
       "      <td>450f41b5d3</td>\n",
       "      <td>2017-02-18 00:10:19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659716</th>\n",
       "      <td>3d7e93cbd0</td>\n",
       "      <td>80d1dae630</td>\n",
       "      <td>2017-06-09 22:46:29</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659717</th>\n",
       "      <td>7804b284a3</td>\n",
       "      <td>0759d2567b</td>\n",
       "      <td>2014-12-28 04:43:49</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659718</th>\n",
       "      <td>6648728db7</td>\n",
       "      <td>28fb7af42b</td>\n",
       "      <td>2013-06-03 00:57:27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659719</th>\n",
       "      <td>e7293de34b</td>\n",
       "      <td>f72dcb10e8</td>\n",
       "      <td>2013-03-09 13:37:35</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            UserId      ItemId           Timestamp  Rating\n",
       "659715  3d7e93cbd0  450f41b5d3 2017-02-18 00:10:19       7\n",
       "659716  3d7e93cbd0  80d1dae630 2017-06-09 22:46:29       7\n",
       "659717  7804b284a3  0759d2567b 2014-12-28 04:43:49       4\n",
       "659718  6648728db7  28fb7af42b 2013-06-03 00:57:27       1\n",
       "659719  e7293de34b  f72dcb10e8 2013-03-09 13:37:35       6"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json('ratings.jsonl', lines=True)\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c4ca4238a0</td>\n",
       "      <td>91766eac45</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c81e728d9d</td>\n",
       "      <td>5c739554f7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c81e728d9d</td>\n",
       "      <td>48f6d7ce7c</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c81e728d9d</td>\n",
       "      <td>e9318d627a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a87ff679a2</td>\n",
       "      <td>17e6357973</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserId      ItemId  Rating\n",
       "0  c4ca4238a0  91766eac45       8\n",
       "1  c81e728d9d  5c739554f7       9\n",
       "2  c81e728d9d  48f6d7ce7c       8\n",
       "3  c81e728d9d  e9318d627a       1\n",
       "4  a87ff679a2  17e6357973       8"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns =[\"Timestamp\"], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51671\n",
      "29674\n"
     ]
    }
   ],
   "source": [
    "#unique users\n",
    "unique_users = df['UserId'].unique()\n",
    "print(len(unique_users))\n",
    "#unique items\n",
    "unique_items = df['ItemId'].unique()\n",
    "print(len(unique_items))\n",
    "\n",
    "ratings = df['Rating'].values\n",
    "\n",
    "user_to_index = {user: i for i, user in enumerate(unique_users)}\n",
    "item_to_index = {item: i for i, item in enumerate(unique_items)}\n",
    "\n",
    "#vectorize unique users and items\n",
    "user_indices = df['UserId'].map(user_to_index).values\n",
    "item_indices = df['ItemId'].map(item_to_index).values   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "learning_rate = 0.007 #Learning rate\n",
    "num_epochs = 20        #Number of epochs\n",
    "num_factors = 30       #Number of latent factors\n",
    "#lambda_l2 = 0.095      #Regularization parameter for L2\n",
    "#lambda_l1 = 0.01       #Regularization parameter for L1\n",
    "regularization = 0.2   #Regularization parameter for user and item biases\n",
    "\n",
    "#number of unique users and items\n",
    "num_users = len(unique_users)\n",
    "num_items = len(unique_items)\n",
    "\n",
    "#initialize user and item matrices with a uniform distribution based on the xavier initialization\n",
    "np.random.seed(12)\n",
    "user_matrix = np.random.uniform(-np.sqrt(6 / (num_users + num_factors)), np.sqrt(6 / (num_users + num_factors)), size=(num_users, num_factors))\n",
    "item_matrix = np.random.uniform(-np.sqrt(6 / (num_items + num_factors)), np.sqrt(6 / (num_items + num_factors)), size=(num_items, num_factors))\n",
    "\n",
    "#dataset ratings mean\n",
    "ratings_mean = np.mean(ratings)\n",
    "\n",
    "#initialize user and item biases as an array of zeros\n",
    "user_bias = np.zeros(num_users)\n",
    "item_bias = np.zeros(num_items)\n",
    "\n",
    "#batch size \n",
    "batch_size = 256\n",
    "\n",
    "#number of batches\n",
    "batch_num = int(len(ratings) / batch_size) \n",
    "\n",
    "#training loop, for each epoch, shuffle the ratings\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #shuffle the ratings, to avoid overfitting\n",
    "    shuffled = np.random.choice(len(ratings), len(ratings), replace=False)\n",
    "\n",
    "    #for each batch, update the user and item matrices and biases\n",
    "    for batch in range(batch_num):\n",
    "\n",
    "        #get the batch indices, by taking the batch size and multiplying it by the batch number\n",
    "        batch_indices = shuffled[batch * batch_size: (batch + 1) * batch_size]\n",
    "        \n",
    "        #get the user and item indices and ratings for the batch by taking the batch indices\n",
    "        user_batch = user_indices[batch_indices]\n",
    "        item_batch = item_indices[batch_indices]\n",
    "        rating_batch = ratings[batch_indices]\n",
    "\n",
    "        #get the user and item matrices for the batch\n",
    "        user_batch_matrix = user_matrix[user_batch, :]\n",
    "        item_batch_matrix = item_matrix[item_batch, :]\n",
    "        \n",
    "        #get the dot product of the user and item matrices, to get the predicted ratings\n",
    "        product = np.sum(user_batch_matrix * item_batch_matrix, axis=1)\n",
    "\n",
    "        #get the predicted ratings by adding the user and item biases and the ratings mean to the dot product\n",
    "        rating_hat = product + user_bias[user_batch] + item_bias[item_batch] + ratings_mean\n",
    "\n",
    "        #calculate the error by subtracting the predicted ratings from the actual ratings\n",
    "        error = rating_batch - rating_hat\n",
    "\n",
    "        #calculate the gradients for the user and item biases, by multiplying the learning rate by the error, adding the regularization terms and the biases\n",
    "        user_bias[user_batch] += learning_rate * (error - regularization * user_bias[user_batch])\n",
    "        item_bias[item_batch] += learning_rate * (error - regularization * item_bias[item_batch])\n",
    "\n",
    "        # Update user and item latent feature matrices for each batch\n",
    "        user_matrix[user_batch, :] += learning_rate * (error[:, np.newaxis] * user_matrix[user_batch, :] - regularization * user_matrix[user_batch, :])\n",
    "        item_matrix[item_batch, :] += learning_rate * (error[:, np.newaxis] * item_matrix[item_batch, :] - regularization * item_matrix[item_batch, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read targets.csv\n",
    "df_targets = pd.read_csv(\"targets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame\n",
    "contentDf = pd.read_json('content.jsonl', lines=True)\n",
    "\n",
    "# Process imdbRating\n",
    "contentDf['imdbRating'] = contentDf['imdbRating'].replace('N/A', np.nan)\n",
    "contentDf['imdbRating'] = contentDf['imdbRating'].astype(float)\n",
    "contentDf['imdbRating'].fillna(contentDf['imdbRating'].mean(), inplace=True)\n",
    "\n",
    "# Convert imdbRating to dictionary\n",
    "imdb_rating_dict = pd.Series(contentDf.imdbRating.values, index=contentDf.ItemId).to_dict()\n",
    "\n",
    "# Process imdbVotes\n",
    "contentDf['imdbVotes'] = contentDf['imdbVotes'].replace('N/A', np.nan)\n",
    "contentDf['imdbVotes'] = contentDf['imdbVotes'].str.replace(',', '').astype(float)\n",
    "contentDf['imdbVotes'].fillna(contentDf['imdbVotes'].mean(), inplace=True)\n",
    "\n",
    "# Convert imdbVotes to dictionary\n",
    "imdb_votes_dict = pd.Series(contentDf.imdbVotes.values, index=contentDf.ItemId).to_dict()\n",
    "\n",
    "df_targets = pd.merge(df_targets, pd.DataFrame(list(imdb_rating_dict.items()), columns=['ItemId', 'imdbRating']), on='ItemId')\n",
    "df_targets = pd.merge(df_targets, pd.DataFrame(list(imdb_votes_dict.items()), columns=['ItemId', 'imdbVotes']), on='ItemId')\n",
    "\n",
    "# Metascore = contentDf[['ItemId', 'Metascore']]\n",
    "\n",
    "# #return number of 'N/A'\n",
    "# print(Metascore['Metascore'].str.count('N/A').sum())\n",
    "\n",
    "# #replace 'N/A' with mean of Metascore\n",
    "# Metascore['Metascore'] = Metascore['Metascore'].replace('N/A', np.nan)\n",
    "# Metascore['Metascore'] = Metascore['Metascore'].astype(float)\n",
    "# Metascore['Metascore'] = Metascore['Metascore'].fillna(Metascore['Metascore'].mean())\n",
    "\n",
    "# #divide by 10\n",
    "# Metascore['Metascore'] = Metascore['Metascore']/10\n",
    "\n",
    "# df_targets = pd.merge(df_targets, Metascore, on='ItemId')\n",
    "\n",
    "\n",
    "\n",
    "# df_targets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Ratings\": [{\"Source\": \"Internet Movie Database\", \"Value\": \"6.7/10\"}, {\"Source\": \"Rotten Tomatoes\", \"Value\": \"12%\"}, {\"Source\": \"Metacritic\", \"Value\": \"29/100\"}]\n",
    "#i want to get a mean of this ratings in 10 scale, keeping in mind maybe theres \"N/A\" values\n",
    "\n",
    "ratingsEnsemble = contentDf[['ItemId', 'Ratings']].copy()\n",
    "\n",
    "\n",
    "# Função para normalizar os ratings para uma escala de 0 a 10\n",
    "def normalize_rating(value):\n",
    "    if '/' in value:\n",
    "        numerator, denominator = value.split('/')\n",
    "        return float(numerator) / float(denominator) * 10\n",
    "    elif '%' in value:\n",
    "        return float(value.strip('%')) / 10\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Função para calcular a média dos ratings de uma linha\n",
    "def calculate_average_ratings(ratings):\n",
    "    normalized_ratings = []\n",
    "    for rating in ratings:\n",
    "        normalized_value = normalize_rating(rating['Value'])\n",
    "        if normalized_value is not None:\n",
    "            normalized_ratings.append(normalized_value)\n",
    "\n",
    "    if normalized_ratings:\n",
    "        return sum(normalized_ratings) / len(normalized_ratings)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Supondo que você já tenha o DataFrame 'ratingsEnsemble'\n",
    "# Vamos aplicar a função a cada linha do DataFrame\n",
    "ratingsEnsemble['AverageRating'] = ratingsEnsemble['Ratings'].apply(calculate_average_ratings)\n",
    "\n",
    "# substituir os valores nulos pela média dos valores não nulos\n",
    "ratingsEnsemble['AverageRating'].fillna(ratingsEnsemble['AverageRating'].mean(), inplace=True)\n",
    "\n",
    "\n",
    "ratingsEnsemble.drop(columns =[\"Ratings\"], inplace = True)\n",
    "# Exibir as primeiras linhas para verificação\n",
    "\n",
    "df_targets = pd.merge(df_targets, ratingsEnsemble, on='ItemId')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create new column fro the rating predictions\n",
    "df_targets['Rating'] = 0\n",
    "\n",
    "\n",
    "#for each pair (user,item) in the targets.csv file, predict the rating and print it\n",
    "for _, row in df_targets.iterrows():\n",
    "\n",
    "    #get the user and item indices\n",
    "    user_index = user_to_index[row['UserId']]\n",
    "\n",
    "    if  row['ItemId'] in item_to_index:\n",
    "        item_index = item_to_index[row['ItemId']]\n",
    "    \n",
    "        svd_rating = (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean) \n",
    "\n",
    "        predicted_rating = svd_rating * row['imdbRating'] * row['imdbVotes'] * row['AverageRating'] \n",
    "              \n",
    "    \n",
    "    else:\n",
    "        svd_rating = ratings_mean\n",
    "        predicted_rating = svd_rating * row['imdbRating'] * row['imdbVotes'] * row['AverageRating'] \n",
    "   \n",
    "    df_targets.at[_, 'Rating'] = predicted_rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by user id, sort the predicted ratings in descending order\n",
    "df_targets.sort_values(by=['UserId', 'Rating'], ascending=[True, False], inplace=True)\n",
    "#df_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the predicted ratings in a csv file, called submission.csv\n",
    "df_targets.drop(columns =[\"Rating\", 'imdbRating', 'imdbVotes', 'AverageRating'], inplace = True)\n",
    "df_targets.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #create new column fro the rating predictions\n",
    "# df_targets['Rating'] = 0\n",
    "\n",
    "\n",
    "# #for each pair (user,item) in the targets.csv file, predict the rating and print it\n",
    "# for _, row in df_targets.iterrows():\n",
    "\n",
    "#     #get the user and item indices\n",
    "#     user_index = user_to_index[row['UserId']]\n",
    "\n",
    "#     if  row['ItemId'] in item_to_index:\n",
    "#         item_index = item_to_index[row['ItemId']]\n",
    "    \n",
    "#         if row['imdbRating'] != \"N/A\":\n",
    "#             # if row['imdbVotes'] != \"N/A\":\n",
    "#             #     predicted_rating = (2 * (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean) + float(row['imdbRating']) + float(row['imdbVotes']) ) / 4\n",
    "#             # else:\n",
    "#                 predicted_rating = (2 * (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean) + float(row['imdbRating'])) / 3\n",
    "          \n",
    "#         else:\n",
    "#             # if row['imdbVotes'] != \"N/A\":\n",
    "#             #     predicted_rating = (2 * (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean) + float(row['imdbVotes'])) / 3\n",
    "#             # else:\n",
    "#                 predicted_rating = (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean)\n",
    "    \n",
    "#     else:\n",
    "#         if row['imdbRating'] != \"N/A\":\n",
    "#             predicted_rating = float(row['imdbRating'])\n",
    "#         # elif row['imdbVotes'] != \"N/A\":\n",
    "#         #     predicted_rating = float(row['imdbVotes'])\n",
    "#         else:\n",
    "#             predicted_rating = ratings_mean\n",
    "#     #if the predicted rating is less than 1, set it to 1\n",
    "#     if float(predicted_rating) < 1:\n",
    "#         predicted_rating = 1\n",
    "\n",
    "#     df_targets.at[_, 'Rating'] = predicted_rating\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #create new column fro the rating predictions\n",
    "# df_targets['Rating'] = 0\n",
    "\n",
    "\n",
    "# #for each pair (user,item) in the targets.csv file, predict the rating and print it\n",
    "# for _, row in df_targets.iterrows():\n",
    "\n",
    "#     #get the user and item indices\n",
    "#     user_index = user_to_index[row['UserId']]\n",
    "\n",
    "#     if  row['ItemId'] in item_to_index:\n",
    "#         item_index = item_to_index[row['ItemId']]\n",
    "    \n",
    "#         if row['imdbRating'] != \"N/A\":\n",
    "#             if row['imdbVotes'] != \"N/A\":\n",
    "#                 predicted_rating = (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean) * float(row['imdbRating']) * float(row['imdbVotes']) \n",
    "#             else:\n",
    "#                 predicted_rating = (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean) * float(row['imdbRating'])\n",
    "          \n",
    "#         else:\n",
    "#             if row['imdbVotes'] != \"N/A\":\n",
    "#                 predicted_rating = (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean) * float(row['imdbVotes'])\n",
    "#             else:\n",
    "#                 predicted_rating = (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean)\n",
    "    \n",
    "#     else:\n",
    "#         if row['imdbRating'] != \"N/A\":\n",
    "#             predicted_rating = float(row['imdbRating'])\n",
    "#         elif row['imdbVotes'] != \"N/A\":\n",
    "#             predicted_rating = float(row['imdbVotes'])\n",
    "#         else:\n",
    "#             predicted_rating = 6\n",
    "#     #if the predicted rating is less than 1, set it to 1\n",
    "#     if float(predicted_rating) < 1:\n",
    "#         predicted_rating = 1\n",
    "\n",
    "#     df_targets.at[_, 'Rating'] = predicted_rating\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #create new column fro the rating predictions\n",
    "# df_targets['Rating'] = 0\n",
    "\n",
    "\n",
    "# #for each pair (user,item) in the targets.csv file, predict the rating and print it\n",
    "# for _, row in df_targets.iterrows():\n",
    "\n",
    "#     #get the user and item indices\n",
    "#     user_index = user_to_index[row['UserId']]\n",
    "\n",
    "#     if  row['ItemId'] in item_to_index:\n",
    "#         item_index = item_to_index[row['ItemId']]\n",
    "    \n",
    "#         if row['AverageRating'] != None:\n",
    "#             # if row['Metascore'] != \"N/A\":\n",
    "#             #     predicted_rating = (3 * (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean) + float(row['imdbRating']) + float(row['Metascore']) / 10) / 5\n",
    "#             # else:\n",
    "#                 predicted_rating = ((np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean) + float(row['AverageRating'])) / 2\n",
    "          \n",
    "#         else:\n",
    "#             # if row['Metascore'] != \"N/A\":\n",
    "#             #     predicted_rating = (2 * (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean) + float(row['Metascore']) / 10) / 3\n",
    "#             # else:\n",
    "#                 predicted_rating = (np.dot(user_matrix[user_index, :], item_matrix[item_index, :].T) + user_bias[user_index] + item_bias[item_index] + ratings_mean)\n",
    "    \n",
    "#     else:\n",
    "#         if row['AverageRating'] != None:\n",
    "#             predicted_rating = float(row['AverageRating'])\n",
    "#         # elif row['Metascore'] != \"N/A\":\n",
    "#         #     predicted_rating = float(row['Metascore']) / 10\n",
    "#         else:\n",
    "#             predicted_rating = 6\n",
    "#     #if the predicted rating is less than 1, set it to 1\n",
    "#     if float(predicted_rating) < 1:\n",
    "#         predicted_rating = 1\n",
    "\n",
    "#     df_targets.at[_, 'Rating'] = predicted_rating\n",
    "\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
